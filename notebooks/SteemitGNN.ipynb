{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6b22489",
   "metadata": {},
   "source": [
    "To install pytorch geometric run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f7d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch=='1.9.0'\n",
    "#!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.9.0+cu102.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76e04ce",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d94c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score,average_precision_score\n",
    "\n",
    "from torch_geometric.utils import negative_sampling\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from torch_geometric.transforms import RandomLinkSplit,NormalizeFeatures,Constant,OneHotDegree\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.nn import GCNConv,SAGEConv,GATConv\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb8b40a",
   "metadata": {},
   "source": [
    "# LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7602b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "current_data = Data()\n",
    "current_data.x = torch.load(\"../data/gnn/node_feature_matrix.pt\")\n",
    "current_data.edge_index = torch.load(\"../data/gnn/edge_index.pt\")\n",
    "\n",
    "#NORMALIZATION (L1-Norm)\n",
    "\n",
    "transform = NormalizeFeatures()\n",
    "current_data = transform(current_data)\n",
    "\n",
    "#TRAIN TEST SPLIT + NEGATIVE SAMPLING\n",
    "transform = RandomLinkSplit(num_val=0.0,num_test=0.25)\n",
    "train_data, val_data, current_test_data = transform(current_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfccd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_data = Data()\n",
    "future_data.x = torch.load(\"../data/gnn/future_node_feature_matrix.pt\")\n",
    "future_data.edge_index = torch.load(\"../data/gnn/future_edge_index.pt\")\n",
    "\n",
    "#NORMALIZATION\n",
    "transform = NormalizeFeatures()\n",
    "future_data = transform(future_data)\n",
    "\n",
    "#NEGATIVE SAMPLING\n",
    "future_neg_edge_index = negative_sampling(\n",
    "        edge_index=future_data.edge_index, #positive edges\n",
    "        num_nodes=future_data.num_nodes, # number of nodes\n",
    "        num_neg_samples=future_data.edge_index.size(1)) # number of neg_sample equal to number of pos_edges\n",
    "\n",
    "#edge index ok, edge_label cat, edge_label_index cat\n",
    "num_pos_edge = future_data.edge_index.size(1)\n",
    "future_data.edge_label = torch.Tensor(np.array([1 for i in range(num_pos_edge)] + [0 for i in range(num_pos_edge)]))\n",
    "future_data.edge_label_index = torch.cat([future_data.edge_index, future_neg_edge_index], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb06308",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f110fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3597e0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MY GNN CUSTOM MODULE\n",
    "class LinkPredModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes, layer = GCNConv, dropout=0.25, loss = torch.nn.BCEWithLogitsLoss):\n",
    "        \n",
    "        super(LinkPredModel, self).__init__()\n",
    "        self.conv1 = layer(input_dim, hidden_dim)\n",
    "        self.conv2 = layer(hidden_dim, num_classes)\n",
    "        \n",
    "        #Initialize the loss function to BCEWithLogitsLoss\n",
    "        self.loss_fn = loss()\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv1.reset_parameters()\n",
    "        self.conv2.reset_parameters()\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x , edge_index, edge_label_index = batch.x.float(), batch.edge_index, batch.edge_label_index\n",
    "        \n",
    "        ## Note\n",
    "        ## 1. Feed the node feature into the first conv layer\n",
    "        ## 2. Add a leaky-ReLU after the first conv layer\n",
    "        ## 3. Add dropout after the ReLU (with probability self.dropout)\n",
    "        ## 4. Repeat for the next layers\n",
    "        ## 5. Select the embeddings of the source nodes and destination nodes\n",
    "        ## by using the edge_label_index and compute the similarity of each pair\n",
    "        ## by dot product\n",
    "\n",
    "        h = self.conv1(x, batch.edge_index)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = F.dropout(h, p=self.dropout)\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = F.leaky_relu(h)\n",
    "        h = F.dropout(h, p=self.dropout)\n",
    "        \n",
    "        h_src = h[edge_label_index[0]]\n",
    "        h_dst = h[edge_label_index[1]]\n",
    "        h_sim = h_src * h_dst #dot product\n",
    "        pred = torch.sum(h_sim, dim=-1)\n",
    "\n",
    "        return pred\n",
    "    \n",
    "    def loss(self, pred, link_label):\n",
    "        return self.loss_fn(pred, link_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c87220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "def train(model, train_data, val_data, test_data, device,\\\n",
    "          optimizer, num_epochs=200, verbose=True):\n",
    "    \n",
    "    avgpr_val_max = 0\n",
    "    best_model = copy.deepcopy(model)\n",
    "    train_data = train_data.to(device)\n",
    "    best_epoch = -1\n",
    "    \n",
    "    avgpr_trains = []\n",
    "    avgpr_vals = []\n",
    "    avgpr_tests = []\n",
    "    \n",
    "    #roc_trains = []\n",
    "    #roc_vals = []\n",
    "    #roc_tests = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        ## Note\n",
    "        ## 1. Zero grad the optimizer\n",
    "        ## 2. Compute loss and backpropagate\n",
    "        ## 3. Update the model parameters\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        #pred = best_model(train_data)\n",
    "\n",
    "        pred = model(train_data)\n",
    "        loss = model.loss(pred, train_data.edge_label.type_as(pred))\n",
    "\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "\n",
    "        ##########################################\n",
    "\n",
    "        log = 'Epoch: {:03d}\\n AVGPR Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n ROC Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n F1-Score Train: {:.4f}, Val: {:.4f}, Test: {:.4f}\\n Loss: {}'\n",
    "        avgpr_score_train, f1_score_train, roc_score_train = test(model, train_data, device)\n",
    "        avgpr_score_val, f1_score_val, roc_score_val = test(model, val_data, device)\n",
    "        avgpr_score_test, f1_score_test, roc_score_test = test(model, test_data, device)\n",
    "        #score_test = test(model, dataloaders['test'], args)\n",
    "        \n",
    "        #f1_trains.append(f1_score_train)\n",
    "        #f1_vals.append(f1_score_val)\n",
    "        #f1_tests.append(f1_score_test)\n",
    "        \n",
    "        avgpr_trains.append(avgpr_score_train)\n",
    "        avgpr_vals.append(avgpr_score_val)\n",
    "        avgpr_tests.append(avgpr_score_test)\n",
    "        \n",
    "        if verbose:\n",
    "            print(log.format(epoch, avgpr_score_train, avgpr_score_val, avgpr_score_test, roc_score_train, roc_score_val, roc_score_test, f1_score_train, f1_score_val, f1_score_test, loss.item()))\n",
    "            \n",
    "        if avgpr_val_max < avgpr_score_val:\n",
    "            avgpr_val_max = avgpr_score_val\n",
    "            best_epoch = epoch\n",
    "            best_model = copy.deepcopy(model)\n",
    "            \n",
    "    if verbose:\n",
    "        print(f'Best Epoch: {best_epoch}')\n",
    "        \n",
    "    return best_model, avgpr_trains, avgpr_vals, avgpr_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79535ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_data, device):\n",
    "    model.eval()\n",
    "    \n",
    "    f1_model_score=0\n",
    "\n",
    "    test_data = test_data.to(device)\n",
    "\n",
    "    h = model(test_data)\n",
    "    \n",
    "    pred_cont = torch.sigmoid(h).cpu().detach().numpy()\n",
    "    pred = [1 if p > 0.5 else 0 for p in pred_cont]\n",
    "\n",
    "    label = test_data.edge_label.cpu().detach().numpy()\n",
    "      \n",
    "    roc_score = roc_auc_score(label, pred_cont)\n",
    "    avgpr_score = average_precision_score(label, pred_cont)\n",
    "    f1_model_score = f1_score(label,pred)\n",
    " \n",
    "    return avgpr_score, f1_model_score, roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a2581",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_data.num_node_features\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b296ee6",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ea6d54",
   "metadata": {},
   "source": [
    "Run this part of the notebook only if you want to re-perform hyperparameter tuning. Below you will find the model with the best config of hypeparameters found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e17870",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_all = {\n",
    "    'optimizer': ['sgd','adam','adagrad'],\n",
    "    'hidden_dim': [4,8,16, 32, 64, 128, 256],\n",
    "    'layer': [GATConv, GCNConv, SAGEConv],\n",
    "    'dropout': [0,0.25,0.50,0.75],\n",
    "    'weight_decay': [5e-5,5e-3,5e-2,5e-1,5e-6],\n",
    "    'lr': [1,0.1,0.075,0.05,0.025,0.01,0.001,0.0001,0.00001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5ae1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_1 = {\n",
    "    'optimizer': ['sgd','adam','adagrad'],\n",
    "    'hidden_dim': [16, 32, 64, 128, 256],\n",
    "    'layer': [GATConv, GCNConv, SAGEConv],\n",
    "    'dropout': [0.25,0.50,0.75],\n",
    "    'lr': [1,0.1,0.01,0.001,0.0001,0.00001]\n",
    "}\n",
    "\n",
    "## USATA PER PRIMI EXP (STRUCT F PERIOD 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ea9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_2 = {\n",
    "    'optimizer': ['sgd','adam','adagrad'],\n",
    "    'hidden_dim': [16,32],\n",
    "    'layer': [GATConv, GCNConv, SAGEConv],\n",
    "    'dropout': [0.0, 0.25],\n",
    "    'lr': [0.1,0.01,0.001]\n",
    "}\n",
    "\n",
    "## USATA PER CONSTANT PERIOD 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4922358",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_3 = {\n",
    "    'optimizer': ['adam'],\n",
    "    'hidden_dim': [16,32],\n",
    "    'layer': [GCNConv],\n",
    "    'dropout': [0.0],\n",
    "    'lr': [0.1,0.01]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93070892",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_4 = {\n",
    "    'optimizer': ['adam'],\n",
    "    'hidden_dim': [4,8],\n",
    "    'layer': [GCNConv],\n",
    "    'dropout': [0.0],\n",
    "    'lr': [0.025,0.05,0.075],\n",
    "    'weight_decay': [5e-5,5e-3,5e-2,5e-1,5e-6]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f578f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnn_tuning(grid, input_dim, num_classes, device, train_data, current_test_data, test_data, logname, fold, plotF1=True):\n",
    "    names, values = zip(*grid.items())\n",
    "    configurations = [dict(zip(names,v)) for v in itertools.product(*values)]\n",
    "    print('There are ', len(configurations), ' configurations for this model')\n",
    "    \n",
    "    i=0\n",
    "    avgpr_max = 0\n",
    "    best_config = {}\n",
    "    best_config_i = 0\n",
    "    weight_decay = 5e-4\n",
    "    with open(logname,'a+') as log:\n",
    "        for config in configurations:\n",
    "            print('Configuration number ', str(i), ' start')\n",
    "            \n",
    "            log.write('CONFIGURATION ' + str(i) + '\\n\\n')\n",
    "            writeConfig = copy.deepcopy(config)\n",
    "            writeConfig['layer'] = writeConfig['layer'].__name__\n",
    "            nameLayer = writeConfig['layer']\n",
    "            log.write(json.dumps(writeConfig,indent=2))\n",
    "            log.write('\\n')\n",
    "\n",
    "            hidden_dim = config['hidden_dim']\n",
    "            layer = config['layer']\n",
    "            dropout = config['dropout']\n",
    "            if 'weight_decay' in config:\n",
    "                weight_decay = config['weight_decay']\n",
    "            model = LinkPredModel(input_dim, hidden_dim, num_classes, dropout = dropout, layer = layer).to(device)\n",
    "            model.reset_parameters()\n",
    "            \n",
    "            opt = config['optimizer']\n",
    "            lr = config['lr']\n",
    "            if opt == 'sgd':\n",
    "                optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "            elif opt == 'adam':\n",
    "                optimizer = torch.optim.Adam(params=model.parameters(), lr=lr, weight_decay = weight_decay)\n",
    "            else:\n",
    "                optimizer = torch.optim.Adagrad(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "            best_model, avgpr_trains, avgpr_vals, avgpr_tests = \\\n",
    "            train(model, train_data, current_test_data, test_data, device, optimizer,verbose=False)\n",
    "            \n",
    "            print('GNN fitted')\n",
    "\n",
    "            avgpr_train, f1_score_train, roc_score_train = test(best_model, train_data, device)\n",
    "            avgpr_val, f1_score_current_test, roc_score_val = test(best_model, current_test_data, device)\n",
    "            avgpr_test, f1_score_future_test, roc_score_test = test(best_model, future_data, device)\n",
    "            \n",
    "            print('GNN performance computed')\n",
    "\n",
    "            log.write('TRAIN SET\\n')\n",
    "            log.write(f' AVGPR SCORE: {avgpr_train}\\n')\n",
    "            log.write(f' ROC SCORE: {roc_score_train}\\n')\n",
    "            log.write(f' F1-SCORE: {f1_score_train}\\n\\n')\n",
    "\n",
    "            log.write('CURRENT TEST SET\\n')\n",
    "            log.write(f' AVGPR SCORE: {avgpr_val}\\n')\n",
    "            log.write(f' ROC SCORE: {roc_score_val}\\n')\n",
    "            log.write(f' F1-SCORE: {f1_score_current_test}\\n\\n')\n",
    "\n",
    "            log.write('FUTURE TEST SET\\n')\n",
    "            log.write(f' AVGPR SCORE: {avgpr_test}\\n')\n",
    "            log.write(f' ROC SCORE: {roc_score_test}\\n')\n",
    "            log.write(f' F1-SCORE: {f1_score_future_test}\\n')\n",
    "            \n",
    "            print('GNN performance written')\n",
    "\n",
    "            if avgpr_max < avgpr_test:\n",
    "                avgpr_max = avgpr_test\n",
    "                best_config = config\n",
    "                best_config_i = i\n",
    "                scores = {\n",
    "                    'avgpr_train': avgpr_train,\n",
    "                    'roc_score_train': roc_score_train,\n",
    "                    'f1_score_train': f1_score_train,\n",
    "                    'avgpr_current_test': avgpr_val,\n",
    "                    'roc_score_val': roc_score_val,\n",
    "                    'f1_score_current_test': f1_score_current_test,\n",
    "                    'avgpr_future_test': avgpr_test,\n",
    "                    'roc_score_test': roc_score_test,\n",
    "                    'f1_score_future_test': f1_score_future_test\n",
    "                }\n",
    "                top_model = copy.deepcopy(best_model)\n",
    "                \n",
    "            if plotF1:\n",
    "                #train orange test blue val green\n",
    "                num_epochs = 200\n",
    "                x = range(num_epochs)\n",
    "                plt.clf()\n",
    "                plt.plot(x, avgpr_trains, color='orange', label='avgpr_train')\n",
    "                plt.plot(x, avgpr_vals, color='green', label='avgpr_val')\n",
    "                plt.plot(x, avgpr_tests, color='blue', label = 'avgpr_test')\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.ylabel('AVGPR-score')\n",
    "                plt.legend()\n",
    "                plt.ylim(top=1)\n",
    "                plt.grid()\n",
    "                plt.savefig(f'learningCurves/{fold}/{nameLayer}_{hidden_dim}_{dropout}_{opt}_{lr}_{weight_decay}.pdf'\\\n",
    "                            ,bbox_inches='tight')\n",
    "                plt.clf()\n",
    "            \n",
    "            print('Configuration number ', str(i), ' end')\n",
    "            print()\n",
    "            \n",
    "            log.write('\\n\\n')\n",
    "            log.flush()\n",
    "\n",
    "            i+=1\n",
    "            \n",
    "        log.write(f'Best configuration number: {best_config_i}\\n')\n",
    "        best_config_write = copy.deepcopy(best_config)\n",
    "        best_config_write['layer'] = best_config_write['layer'].__name__\n",
    "        log.write(json.dumps(best_config_write,indent=2))\n",
    "        log.write('\\n')\n",
    "        log.write(json.dumps(scores,indent=2))\n",
    "        log.write('\\n')\n",
    "        log.flush()\n",
    "        log.close()\n",
    "        \n",
    "    return top_model, best_config, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab5cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, best_config, scores = gnn_tuning(grid_4, input_dim, num_classes, device, train_data, current_test_data, future_data, 'new_grid_gnn_text_august2016.txt', 'GNN/new_grid/text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd84cad",
   "metadata": {},
   "source": [
    "## Single Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed96eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinkPredModel(input_dim, 16, num_classes, dropout=0.0, layer=GCNConv).to(device)\n",
    "model.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfebad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 5e-4\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=weight_decay)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01, weight_decay = weight_decay)\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=0.1, weight_decay = weight_decay)\n",
    "#optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee3d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model , prtrain , prval, prtest = train(model, train_data, current_test_data, future_data, device, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d329ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train orange test blue val green\n",
    "num_epochs = 200\n",
    "x = range(num_epochs)\n",
    "plt.clf()\n",
    "plt.plot(x, prtrain, color='orange', label='avgpr_train')\n",
    "plt.plot(x, prval, color='green', label='avgpr_val')\n",
    "plt.plot(x, prtest, color='blue', label = 'avgpr_test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AVGPR-score')\n",
    "plt.legend()\n",
    "plt.ylim(top=1)\n",
    "plt.grid()\n",
    "plt.savefig(f'new_AVGPR_learningCurve_GNNAll_august2016.pdf',bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25793224",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_train, f1_score_train = test(best_model, train_data, device)\n",
    "roc_val, f1_score_current_test = test(best_model, current_test_data, device)\n",
    "roc_test, f1_score_future_test = test(best_model, future_data, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5500cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TRAIN SET')\n",
    "print(f' ROC AUC SCORE: {roc_train}')\n",
    "print(f' F1-SCORE: {f1_score_train}')\n",
    "\n",
    "print()\n",
    "\n",
    "print('CURRENT TEST SET')\n",
    "print(f' ROC AUC SCORE: {roc_val}')\n",
    "print(f' F1-SCORE: {f1_score_current_test}')\n",
    "\n",
    "print()\n",
    "\n",
    "print('FUTURE TEST SET')\n",
    "print(f' ROC AUC SCORE: {roc_test}')\n",
    "print(f' F1-SCORE: {f1_score_future_test}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
